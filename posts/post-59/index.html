<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Видеозахват на Raspberry Pi. Часть 2: Software – urpylka՚s blog!</title><link rel="icon" type="image/x-icon" href="https://urpylka.com/favicon.ico" />
	<link rel="apple-touch-icon" sizes="57x57" href="https://urpylka.com/favicon/apple-icon-57x57.png">
	<link rel="apple-touch-icon" sizes="60x60" href="https://urpylka.com/favicon/apple-icon-60x60.png">
	<link rel="apple-touch-icon" sizes="72x72" href="https://urpylka.com/favicon/apple-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="76x76" href="https://urpylka.com/favicon/apple-icon-76x76.png">
	<link rel="apple-touch-icon" sizes="114x114" href="https://urpylka.com/favicon/apple-icon-114x114.png">
	<link rel="apple-touch-icon" sizes="120x120" href="https://urpylka.com/favicon/apple-icon-120x120.png">
	<link rel="apple-touch-icon" sizes="144x144" href="https://urpylka.com/favicon/apple-icon-144x144.png">
	<link rel="apple-touch-icon" sizes="152x152" href="https://urpylka.com/favicon/apple-icon-152x152.png">
	<link rel="apple-touch-icon" sizes="180x180" href="https://urpylka.com/favicon/apple-icon-180x180.png">
	<link rel="icon" type="image/png" sizes="192x192"  href="https://urpylka.com/favicon/android-icon-192x192.png">
	<link rel="icon" type="image/png" sizes="32x32" href="https://urpylka.com/favicon/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="96x96" href="https://urpylka.com/favicon/favicon-96x96.png">
	<link rel="icon" type="image/png" sizes="16x16" href="https://urpylka.com/favicon/favicon-16x16.png">
	<link rel="manifest" href="https://urpylka.com/favicon/manifest.json">
	<meta name="msapplication-TileColor" content="#ffffff">
	<meta name="msapplication-TileImage" content="https://urpylka.com/favicon/ms-icon-144x144.png">
	<meta name="theme-color" content="#ffffff"><meta itemprop="name" content="Видеозахват на Raspberry Pi. Часть 2: Software">
<meta itemprop="description" content="Это вторая статья из серии про работу с видео-устройствами на Raspberry Pi. Если в первой статье я делал акцент на физические ограничения компьютера, то в этой я постараюсь описать общие принципы работы с видео-устройствами в плоскости софта.">
<meta itemprop="datePublished" content="2021-11-05T23:36:00&#43;04:00" />
<meta itemprop="dateModified" content="2021-11-05T23:36:00&#43;04:00" />
<meta itemprop="wordCount" content="1641">



<meta itemprop="keywords" content="ru,programming,raspberrypi,camera,videocapture," /><meta property="og:title" content="Видеозахват на Raspberry Pi. Часть 2: Software" />
<meta property="og:description" content="Это вторая статья из серии про работу с видео-устройствами на Raspberry Pi. Если в первой статье я делал акцент на физические ограничения компьютера, то в этой я постараюсь описать общие принципы работы с видео-устройствами в плоскости софта." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://urpylka.com/posts/post-59/" />
<meta property="article:published_time" content="2021-11-05T23:36:00+04:00" />
<meta property="article:modified_time" content="2021-11-05T23:36:00+04:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Видеозахват на Raspberry Pi. Часть 2: Software"/>
<meta name="twitter:description" content="Это вторая статья из серии про работу с видео-устройствами на Raspberry Pi. Если в первой статье я делал акцент на физические ограничения компьютера, то в этой я постараюсь описать общие принципы работы с видео-устройствами в плоскости софта."/>
<link rel="stylesheet" type="text/css" media="screen" href="https://urpylka.com/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://urpylka.com/css/main.css" />
	<link rel="stylesheet" type="text/css" id="dark-scheme" href="https://urpylka.com/css/dark.css" />
	<link rel="stylesheet" type="text/css" href="https://urpylka.com/css/medium-font.css" />
<script type="text/javascript" >
	(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
	m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
	(window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");
ym("62022457", "init", {
        clickmap:true,
        trackLinks:true,
        accurateTrackBounce:true,
        webvisor:true
});
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/62022457" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-163829261-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script><script src="https://urpylka.com/js/main.js"></script></head>


<body>
    <div class="container wrapper">
        <div class="header"><div class="flex-block">
		<div class="site-title"><a href="https://urpylka.com/">urpylka՚s blog!</a></div>
		<nav class="nav ico">
			<ul class="flat"><li><a href="https://github.com/urpylka" title="Github"><i data-feather="github"></i></a></li><li><a href="https://instagram.com/urpylka" title="Instagram"><i data-feather="instagram"></i></a></li><li class="edge-left"><span class="scheme-toggle"><a href="#" id="scheme-toggle"></a></span></li>
			</ul>
		</nav>
	</div><p id="subtitle">Programming, robotics, traveling</p><nav class="nav menu">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">Posts</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


        <div class="post one">
            <div class="post-header">
                
                <div class="meta">
                    <div class="date">
                        <span class="day">05</span>
                        <span class="rest">Nov 2021</span>
                    </div>
                </div>
                
                <div class="matter">
                    <h1 class="title">Видеозахват на Raspberry Pi. Часть 2: Software</h1>
                </div>
            </div>

            <div class="markdown">
                <hr>
<p>Навигация по серии статей:</p>
<ol>
<li><a href="/posts/post-17/">Видеозахват на Raspberry Pi. Часть 1: Hardware</a></li>
<li><a href="/posts/post-59/">Видеозахват на Raspberry Pi. Часть 2: Software</a></li>
</ol>
<hr>
<p>Это вторая статья из серии про работу с видео-устройствами на Raspberry Pi. Если в первой статье я делал акцент на физические ограничения компьютера, то в этой я постараюсь описать общие принципы работы с видео-устройствами в плоскости софта. На это  меня подтолкнуло собственное непонимание общей картины как стримится видео. И сколько я не читал статей, получалось всё хуже – сколько людей, столько и способов. Потратив кучу времени мне удалось структурировать знания и для того, чтобы моё время было потрачено не зря, а все знания не забылись через год, я и пишу эту статью.</p>
<h2 id="video4linux-устройства">Video4Linux устройства</h2>
<p>Начать исследование системы на наличие камер и других устройств по работе с аудио-видео устройствами советую с подключенных <a href="https://ru.wikipedia.org/wiki/Video4Linux"><code>Video4Linux</code></a> устройств (подробнее в статье <a href="https://russianblogs.com/article/75982204567/">V4L2 Глубокое понимание</a>). Сделать это можно с помощью следующей утилиты – <a href="https://www.mankier.com/1/v4l2-ctl"><code>v4l2-ctl</code></a>.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#008000"># Display all information available.</span>
v4l2-ctl --all

<span style="color:#008000"># List all v4l devices. If -z was given, then list just the devices of the media device with the bus info string as specified by the -z option.</span>
v4l2-ctl --list-devices

<span style="color:#008000"># List available capture formats, you can set device with -d flag</span>
v4l2-ctl --list-formats
v4l2-ctl --list-formats-ext
</code></pre></div><p>Также, если камера подключена через USB можно проверить это подключение следующими способами:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">lsmod
lsusb
cat /sys/kernel/debug/usb/devices
</code></pre></div><p>Для проверки как в системе опрделилось устройство можно воспользоваться утилитой <code>udevadm</code>. Пример вывода <code>Raspicam V1.2</code>:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">pi@theimage-6786:~ $ udevadm info /dev/video0
P: /devices/virtual/video4linux/video0
N: video0
L: 0
E: DEVPATH=/devices/virtual/video4linux/video0
E: DEVNAME=/dev/video0
E: MAJOR=81
E: MINOR=0
E: SUBSYSTEM=video4linux
E: USEC_INITIALIZED=12812306
E: ID_V4L_VERSION=2
E: ID_V4L_PRODUCT=mmal service 16.1
E: ID_V4L_CAPABILITIES=:capture:video_overlay:
E: TAGS=:uaccess:seat:
</code></pre></div><blockquote>
<p>При перезагрузке и подключении камер той же версии меняется только параметр <code>USEC_INITIALIZED</code>.</p>
</blockquote>
<h2 id="raspistill-raspivid-and-libcamera">raspistill, raspivid and libcamera</h2>
<p>Образы <code>Raspberry Pi OS</code> начиная с версии <code>Bullseye</code> содержат в себе <code>libcamera</code> стэк. Образа до и включительно <code>Buster</code> содержут в себе <code>Raspicam</code> стэк. Причиной отказа от стэка <code>Raspicam</code> стали проприетарные исходники Broadcom GPU, которые не позволяли в полной мере поддерживать его работу (подробнее об этом <a href="https://www.raspberrypi.com/documentation/accessories/camera.html#libcamera-and-the-legacy-raspicam-camera-stack">здесь</a>).</p>
<blockquote>
<p>Для старых версий можно собрать <code>libcamera</code> стэк согласно <a href="https://www.raspberrypi.com/documentation/accessories/camera.html#building-libcamera-and-libcamera-apps">этой инструкции</a>.</p>
</blockquote>
<p>Основная информация касаемо использования <code>libcamera</code> описана в прекрасной документации на <a href="https://www.raspberrypi.com/documentation/accessories/camera.html">raspberrypi.com</a> и её пересказывать не вижу смысла. Однако считаю важным подчеркнуть минусы перехода на новый стэк.</p>
<ul>
<li><code>libcamera</code> стэк содержит утилиты <code>libcamera-still</code> и <code>libcamera-vid</code> для замены <code>raspistill</code> и <code>raspivid</code>. Однако в отличии от <code>Raspicam</code> в новом стеке есть лишь небольшая прослойка для общения с <code>Broadcom GPU</code>, и все операции выполняются на ARM-ядрах. Тоесть по-сути эти утилиты кодируют на <code>CPU</code> вместо <code>GPU</code>, что снижает общую производительность и может вызвать большие проблемы на <code>Raspberry Pi 2</code> и <code>Raspberry Pi Zero</code> где всего одно ядро.</li>
<li><code>libcamera</code> до сих пор не содержит некоторых фич, в первую очередь биндингов для Python (они находятся в разработке).</li>
</ul>
<blockquote>
<p>Также небольшим замечанием будет то, что по умолчанию <code>libcamera</code> не уставлен в ОС, помимо установки нужно еще сконфигурировать выбор используемой камеры.</p>
</blockquote>
<p>Немного про использование <code>Raspicam</code>:</p>
<ul>
<li><a href="http://www.avislab.com/blog/raspberry-pi-camera_ru/">avislab.com</a></li>
</ul>
<h2 id="аппаратное-кодирование">Аппаратное кодирование</h2>
<p>Помимо использования <code>Raspicam</code> для аппаратного кодирования с помощью <code>GPU</code> у меня опыта нет. Но в целом для работы с графическим сопроцессором есть два API: <code>MMAL</code> и <code>OpenMAX</code>. Тут нужно сделать пометку что <code>MMAL</code> построено на более низкоуровневом <code>OpenMAX</code> (<a href="http://wikihandbk.com/wiki/Raspberry_Pi:%D0%9E%D0%BF%D0%B5%D1%80%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BC%D0%B0/Raspbian_OS/%D0%9F%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D1%8B/%D0%9A%D0%B0%D0%BC%D0%B5%D1%80%D0%B0">wikihandbk.com</a>). Собственного опыта работы с этими API у меня нет, поэтому ниже будет просто много ссылок на эту тему:</p>
<ul>
<li><a href="https://habrahabr.ru/company/intel/blog/207314/">Raspberry Pi: Кодируем H.264 видео в реальном времени</a></li>
<li><a href="https://github.com/gagle/raspberrypi-openmax-h264">github.com/gagle/raspberrypi-openmax-h264)</a>: (<a href="https://github.com/gagle/raspberrypi-openmax-h264/network">network graph</a>, <a href="https://github.com/whdlgp/raspberrypi-openmax-h264">форк c диаграммами</a>]</li>
<li><a href="https://www.linuxquestions.org/questions/showthread.php?p=5729051">Raspberry Pi: How to compile OpenMAX and FFMPEG on RPi</a></li>
<li><a href="https://ubuntu-mate.community/t/hardware-h264-video-encoding-with-libav-openmax-il/4997">Hardware h264 video encoding with libav (openmax IL)</a>
*<a href="http://solitudo.net/software/raspberrypi/rpi-openmax-demos/">OpenMAX IL demos for Raspberry Pi</a></li>
<li><a href="http://blog.oklahome.net/2014/09/what-ive-learned-about-mmal-raspberry.html">What I&rsquo;ve learned about MMAL and picamera: Raspberry Pi drive recorder with GPS logger</a></li>
<li><a href="https://wiki.matthiasbock.net/index.php/Hardware-accelerated_video_playback_on_the_Raspberry_Pi">Hardware-accelerated video playback on the Raspberry Pi</a></li>
</ul>
<p>Аппаратное кодирование с <code>gstreamer</code>:</p>
<ul>
<li>Gstreamer with openmax <a href="https://http503.wordpress.com/2014/11/14/using-gstreamer-with-openmax-in-a-raspberry-pi/">http503.wordpress.com</a></li>
<li>Подробно про videocore <a href="https://elinux.org/Raspberry_Pi_VideoCore_APIs">elinux.org</a></li>
<li>openmax gstreamer <a href="http://web.archive.org/web/20190423162313/http://gstreamer-devel.966125.n4.nabble.com/omxh264enc-and-stream-format-string-avc-td4671543.html">gstreamer-devel.966125.n4.nabble.com</a></li>
<li>openmax gstreamer <a href="https://www.raspberrypi.org/forums/viewtopic.php?t=6852#p100055">raspberrypi.org</a></li>
<li><a href="http://web.archive.org/web/20180706090839/http://emmanuelgranatello.blogspot.com/2013/10/raspberry-pi-gstreamer-streaming-h264.html">Raspberry Pi - Gstreamer streaming H.264 with OpenMax</a></li>
</ul>
<h2 id="захват-одиночных-изображений">Захват одиночных изображений</h2>
<p>Помимо <code>raspistill</code>, <code>libcamera-still</code> (которые работают с камерой подключенной с помощью CSI-интерфейса) для захвата одиночных изображений Raspberry Foundation <a href="https://www.raspberrypi.com/documentation/computers/os.html#using-a-usb-webcam">предлагает использовать</a> <code>fswebcam</code>.</p>
<p><code>fswebcam</code> – консольное приложение, используемое для создания одиночных изображений c веб-камеры. Оно захватывает ряд кадров с <code>V4L</code> или <code>V4L2</code> совместимого устройства, усредняет их для уменьшения шума и рисует на них детали с помощью графической библиотеки (<code>LibGD</code>), которая также выполняет сжатие изображения в <code>PNG</code>, <code>JPEG</code> или <code>WEBP</code>.</p>
<ul>
<li>Official site <a href="http://www.sanslogic.co.uk/fswebcam/">sanslogic.co.uk/fswebcam</a></li>
<li>Official repo <a href="https://github.com/fsphil/fswebcam">github.com/fsphil/fswebcam</a></li>
</ul>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#008000"># Capture one frame</span>
fswebcam /dev/video0 image.jpg

<span style="color:#008000"># Get additional info</span>
fswebcam -d v4l2:/dev/video0 -i 0 --list-controls
</code></pre></div><p>Дополнительную информацию по использованию <code>fswebcam</code> вы можете найти ниже:</p>
<ul>
<li><a href="https://www.ekzorchik.ru/2017/02/simple-operation-via-the-usb-camera-fswebcam/">ekzorchik.ru</a></li>
<li><a href="https://zenway.ru/page/fswebcam">zenway.ru</a></li>
<li><a href="https://habr.com/ru/post/200934/">habr.com</a></li>
<li><a href="http://forum.amperka.ru/threads/%D0%9F%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D1%8B-%D1%81-%D0%BF%D0%BE%D0%BB%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC-%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F-%D0%B2%D0%B5%D0%B1-%D0%BA%D0%B0%D0%BC%D0%B5%D1%80%D1%8B.18307/">forum.amperka.ru</a></li>
</ul>
<h2 id="видеозахват">Видеозахват</h2>
<p>Для того, чтобы записать видеоролик, нужно в разрешенном для видео-устройства формате (сжатии) считать данные из интерфейса. При необходимости, сконвертировать данный поток в нужный формат и записать на диск. Одним из самых известных инструментов для этой задачи является <a href="https://ffmpeg.org"><code>ffmpeg</code></a>.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash"><span style="color:#008000"># List device capabilities</span>
ffmpeg -f v4l2 -list_formats all -i /dev/video0

<span style="color:#008000"># Record</span>
ffmpeg -f v4l2 -framerate 25 -video_size 640x480 -i /dev/video0 output.mkv

<span style="color:#008000"># Converting</span>
ffmpeg -i input.mp4 output.avi
</code></pre></div><p>Немного ссылок по работе с ним:</p>
<ul>
<li><a href="https://trac.ffmpeg.org/wiki/Capture/Webcam">trac.ffmpeg.org</a>: wiki по захвату видео</li>
<li><a href="https://losst.ru/poleznye-komandy-ffmpeg">losst.ru</a>: Полезные команды ffmpeg</li>
<li><a href="https://habr.com/ru/post/536170/">habr.com</a>: обрезка видео, склейка, размещение видео рядом</li>
<li><a href="https://github.com/tgogos/rpi_ffmpeg">github.com/tgogos/rpi_ffmpeg</a>: FFmpeg on Raspberry Pi 3 with h264 support</li>
<li><a href="https://askubuntu.com/questions/881305/is-there-any-way-ffmpeg-send-video-to-dev-video0-on-ubuntu">askubuntu.com</a>: loopback camera device</li>
</ul>
<h2 id="стриминг-видео">Стриминг видео</h2>
<p>Для начала думаю важно описать что такое стрим видео. Я представляю себе этот процесс как конвеер, пройдёмся по нему:</p>
<ol>
<li>Видеопоток нужно захватить некоторой программой, обычно той, которая может его перекодировать в нужный нам формат из того, который предлагает драйвер операционной системы.</li>
<li>Если необходимо помимо перекодирования видео-потока, произвести его изменение. Например, изменить его частоту, разрешение, наложить текст, добавить аудио.</li>
<li>Передать этот результирующий видео-поток дальше – например, сохранить его в файл или передать по сокету (например, некоторому приложению).</li>
<li>Если мы хотим реализовать стрим, то нам необходим веб-сервер, который сможет отдавать видео-поток клиентам. Кстати за протокол отдачи стрима в этом случае отвечает веб-сервер. Сравнение протоколов <code>RTSP/RTP</code>, <code>Adobe RTMP</code>, <code>WebRTC</code>, <code>FTL</code>, <code>SRT</code>, <code>MPEG-DASH</code>, <code>Apple HLS</code>, <code>LL-HLS</code> можно найти на <a href="https://restream.io/blog/streaming-protocols/">restream.io</a>, <a href="https://www.wowza.com/blog/streaming-protocols">wowza.com</a>.</li>
</ol>
<p>При выборе протокола для стрима большое значение имеет поддерживаемый протоколом кодек. Кодек – это алгоритм сжатия видео. Можно выделить два основных вида сжатия: <code>покадровое сжатие</code> и <code>межкадровое сжатие</code>. Подробнее про кодеки:</p>
<ul>
<li><a href="https://vstarcam.ua/technology/codec-h264-mpeg4-mjpeg/">vstarcam.ua</a></li>
<li><a href="http://www.cctv.groteck.ru/articles.php?topic=1&amp;article=8">cctv.groteck.ru</a> (мне кажется тут есть ошибка касаемо MJPEG)</li>
</ul>
<h3 id="mjpeg-by-mjpg-streamer">MJPEG by mjpg-streamer</h3>
<p>Реализацией метода покадрового сжатия является Motion JPEG (MJPEG) (<a href="https://ru.wikipedia.org/wiki/MJPEG">wiki</a>). Основной особенностью которого является сжатие каждого отдельного кадра видеопотока с помощью алгоритма сжатия изображений JPEG. Этот метод широко применяется в некритичных к задержкам задачах, например в видеонаблюдении. Плюсами данного метода являются: небольшие потребности в ресурсах вычислителя при кодировании, поддержка отображения данного стрима с помощью всех браузеров без надстроек. Возможность легко добавить веб-сервер для повышения робастности камеры. Реализацией данного метода является <a href="https://sourceforge.net/projects/mjpg-streamer/"><code>mjpg-streamer</code></a>.</p>
<p>Надо заметить, что в дистрибутивах <code>Raspbian OS</code> (до <code>RaspiOS</code>) утилита <code>raspistill</code> для кодирования изображений с CSI-камеры использовала возможности аппаратного видео-сопроцессора <code>Video Core</code>. И по сути позволяла не использовать для этого ресурсы CPU. Такая возможность была добавлена в <code>mjpg-streamer</code> за счет добавления плагина <a href="https://github.com/jacksonliam/mjpg-streamer"><code>input_raspicam</code></a>.</p>
<p><img src="./images/screenshot-2017-09-28-v-20.03.17.png" alt="image"></p>
<p>Использование <code>mjpg-streamer</code>:</p>
<ul>
<li><a href="https://habr.com/ru/post/196598/">Фотонаблюдение или timelapse видео на Raspberry Pi</a></li>
<li><a href="https://savepearlharbor.com/?p=200934">Timelapse с элементами видеонаблюдения</a></li>
<li><a href="https://m.habr.com/en/post/180227/">Как с помощью Raspberry PI вырастить фасоль, и снять TimeLapse видео</a></li>
<li><a href="https://raspberrypi.ru/551-raspberry-pi-i-mjpg-streamer-ili-videotranslyatsiya-s">Raspberry Pi и mjpg-streamer</a></li>
<li><a href="http://www.%D0%B2%D0%BE%D0%BB%D1%8C%D1%82%D0%BC%D0%B0%D1%81%D1%82%D0%B5%D1%8061.%D1%80%D1%84/articles/68339">вольтмастер61.рф</a>: fswebcam, motion, mjpg-streamer, ffmpeg, avconv</li>
<li><a href="http://www.poprobot.ru/home/raspberrypi-webcam">poprobot.ru</a>: mjpg-streamer-rpi, fswebcam, v4l2-ctl</li>
<li>Интересный способ стриминга <a href="https://www.raspberrypi.org/forums/viewtopic.php?f=43&amp;t=45178">raspberrypi.org</a></li>
<li>хорошая справка про fjpg-streamer на <a href="http://skillfulness.blogspot.ru/2010/03/mjpg-streamer-documentation.html">skillfulness.blogspot.ru</a></li>
<li><a href="https://github.com/foosel/OctoPrint/wiki/MJPG-Streamer-configuration">github.com/foosel/OctoPrint/wiki/MJPG-Streamer-configuration</a></li>
<li><a href="https://github.com/sunfounder/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi/tree/master/mjpg-streamer">github.com/sunfounder/Sunfounder_Smart_Video_Car_Kit_for_RaspberryPi</a></li>
<li><a href="http://web.archive.org/web/20170704164651/http://www.howtoembed.com/projects/raspberry-pi/78-pieye-webcam-streaming-in-m-jpg-format-with-raspberry-pi">howtoembed.com</a></li>
<li><a href="https://github.com/meinside/rpi-mjpg-streamer/blob/master/run-mjpg-streamer.sh.sample">обертка для fjpg-streamer</a></li>
</ul>
<h3 id="сырой-байтовый-поток-в-h264-в-udp--tcp">Сырой байтовый поток в H.264 в UDP / TCP</h3>
<p>Для организации стрима двумя видами сжатия в тч с межкадровым нужно использовать другие видеокодеки, например, <code>H.264</code>. Большинство камер сразу отдает видеопоток с сжатием в этом кодеке. А те же утилиты <code>raspivid</code>, <code>libcamera-vid</code> могут выдавать в stdout непосредственно байтовый поток который можно передать по сети используя тот же <code>netcat</code> (<code>nc</code>).</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">raspivid -t 0 -h 240 -w 320 -fps 30 -hf -b 100000  -o - | nc -l 5001
</code></pre></div><p>В <code>libcamera-vid</code> также появился механизм передачи байтового потока по сети:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">libcamera-vid -t 0 --inline -o udp://&lt;ip-addr&gt;:&lt;port&gt;
</code></pre></div><p>Подробнее здесь на сайте <a href="https://www.raspberrypi.com/documentation/accessories/camera.html#network-streaming">raspberrypi.com</a>.</p>
<p>Аналогичный стрим можно сделать с помощью <code>ffmpeg</code>:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">ffmpeg -f v4l2 -s 640x480 -input_format mjpeg -i /dev/video0 -c:v copy -f mjpeg udp://ip:port
</code></pre></div><p>Ребята из <a href="https://habr.com/ru/company/singularis/profile/">Singularis Lab</a> переделали <code>mpjg-streamer</code> под передачу <code>H.264</code> подробнее в <a href="https://habr.com/ru/company/singularis/blog/343362/">статье на хабре</a>.</p>
<p>Подробнее про кодеки для межкадрового сжатия написано <a href="https://habr.com/ru/company/wd/blog/511966/">в этой статье</a>. Их поддержку камерами нужно проверять. Или, если это необходимо, можно сделать переконвертацию в нужный кодек, используя тот же <code>ffmpeg</code>.</p>
<p>Однако <code>H.264</code> без обертки не предназначен для передачи по сети. А также большинство плееров не смогут воспроизвести такой поток. Далее рассмотрим проколы для потокового видео.</p>
<h4 id="adobe-rtmp-by-ffmpeg-ffserver">Adobe RTMP by ffmpeg, ffserver</h4>
<p>Для стриминга с помощью <code>ffmpeg</code> нужен веб-сервер. Раньше для стрима с помощью <code>ffmpeg</code> использовался входящий в его пакет <code>ffserver</code>, однако 6 января 2018 года его удалили. Подробнее о как использовать <code>ffserver</code>:</p>
<ul>
<li><a href="https://trac.ffmpeg.org/wiki/ffserver">trac.ffmpeg.org</a></li>
<li><a href="https://zenway.ru/page/ffserver">zenway.ru</a></li>
<li><a href="https://habr.com/ru/post/78677/">habr.com</a></li>
<li><a href="https://gist.github.com/peterhellberg/ebfc72147c2009ee720aafe57ce9c141">gist.github.com</a></li>
<li><a href="https://www.dynamsoft.com/codepool/raspberry-pi-live-streaming-usb-webcam.html">dynamsoft.com</a></li>
</ul>
<p><code>ffserver</code> предлагает два потока: в формате <code>FLV</code> и <code>SWF</code>.</p>
<p>В источниках ниже изложено как использовать <code>ffmpeg</code> с <code>RTMP</code> плагином на <code>nginx</code>:</p>
<ul>
<li><a href="https://andreyv.ru/ffmpeg-potokovoe-veshhanie-dlya-chajjnikov.html">andreyv.ru</a></li>
<li><a href="https://habr.com/ru/post/174089/">habr.com</a></li>
</ul>
<p>Тут нужно сделать замечание: <code>RTMP</code> является проприетарным проколом Adobe, который был разработан для работы с <code>Flash Player</code>. И соответственно как и он - протокол устарел.</p>
<p>Также есть интересные ветки для ведения прямой передачи потока на YouTube без использования веб-сервера по RTMP протоколу:</p>
<ul>
<li><a href="https://www.raspberrypi.org/forums/viewtopic.php?t=212417">raspberrypi.org</a></li>
<li><a href="https://codengineering.ru/q/ispolzovanie-ffmpeg-dlya-translyacii-video-s-moey-veb-kamery-na-youtube-zakryto-31356">codengineering.ru</a></li>
</ul>
<p>Вместо <code>ffserver</code> на сайте <a href="https://trac.ffmpeg.org/wiki/ffserver">trac.ffmpeg.org</a> предлагают использовать <a href="https://github.com/klaxa/mkvserver_mk2">mkvserver_mk2</a>.</p>
<h3 id="rtsprtp">RTSP/RTP</h3>
<p>Реализация обертки в RTSP прокол посредством <code>VLC</code>.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">libcamera-vid -t 0 --inline -o - | cvlc stream://dev/stdin --sout <span style="color:#a31515">&#39;#rtp{sdp=rtsp://:8554/stream1}&#39;</span> :demux=h264
</code></pre></div><p>Подробнее:</p>
<ul>
<li><a href="https://www.raspberrypi.com/documentation/accessories/camera.html#rtsp">raspberrypi.com</a></li>
<li><a href="https://habr.com/ru/post/252587/">Трансляция видео с Raspberry Pi</a></li>
</ul>
<p>Реализация обертки в RTSP прокол посредством <code>gstreamer</code>.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">libcamera-vid -t 0 -n --inline -o - | gst-launch-1.0 fdsrc fd=0 ! h264parse ! rtph264pay ! udpsink host=localhost port=5000
</code></pre></div><p>Кстати благодаря тому, что <code>libcamera</code> предоставяляет <code>libcamerasrc</code> gstreamer элемент, возможен прямой запуск gstreamer'а.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-bash" data-lang="bash">gst-launch-1.0 libcamerasrc ! capsfilter caps=video/x-raw,width=1280,height=720,format=NV12 ! v4l2convert ! v4l2h264enc extra-controls=<span style="color:#a31515">&#34;controls,repeat_sequence_header=1&#34;</span> ! h264parse ! rtph264pay ! udpsink host=localhost port=5000
</code></pre></div><p>Подробнее про использование gstreamer:</p>
<ul>
<li><a href="https://www.raspberrypi.com/documentation/accessories/camera.html#using-gstreamer">raspberrypi.com</a></li>
<li><a href="https://habr.com/en/post/258377/">Трансляция видео с Raspberry Pi по 3G тремя способами</a></li>
<li><a href="https://habr.com/en/post/153611/">Raspberry Pi. Передача видео для дистанционного управления</a></li>
<li><a href="https://raspberrypi.stackexchange.com/questions/27082/how-to-stream-raspivid-to-linux-and-osx-using-gstreamer-vlc-or-netcat">How to stream raspivid to Linux and OSX using GStreamer, VLC or Netcat?</a></li>
<li><a href="https://stackoverflow.com/questions/17313985/stream-h-264-video-over-rtp-using-gstreamer">Stream H.264 video over rtp using gstreamer</a></li>
</ul>
<h2 id="другие-ссылки-по-теме">Другие ссылки по теме</h2>
<ul>
<li>Web based interface for controlling the Raspberry Pi Camera, includes motion detection, time lapse, and image and video recording. <a href="https://github.com/silvanmelchior/RPi_Cam_Web_Interface">github.com/silvanmelchior/RPi_Cam_Web_Interface</a></li>
<li>Комбайн <code>avconv</code>. <a href="https://libav.org/avconv.html#Description">libav.org</a>, <a href="https://andy.od.ua/news_55.html">andy.od.ua</a>, <a href="https://superuser.com/questions/877068/avconv-stream-video-from-usb-webcam-without-delay">superuser.com</a></li>
<li>Стриминг с минимальными задержками <a href="https://raspberrypi.stackexchange.com/questions/42881/how-to-stream-low-latency-video-from-the-rpi-to-a-web-browser-in-realtime">raspberrypi.stackexchange.com</a>, <a href="http://pnetherwood.blogspot.ru/2015/04/raspberry-pi-video-streaming-to-android.html">pnetherwood.blogspot.ru</a></li>
<li>Стриминг на сайт <a href="http://forum.amperka.ru/threads/%D0%9F%D0%B5%D1%80%D0%B5%D0%B4%D0%B0%D1%87%D0%B0-%D0%B2%D0%B8%D0%B4%D0%B5%D0%BE-%D1%81-%D0%BC%D0%BE%D0%B4%D1%83%D0%BB%D1%8F-%D0%BA%D0%B0%D0%BC%D0%B5%D1%80%D1%8B-%D0%BD%D0%B0-%D0%BB%D0%BE%D0%BA%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B9-%D0%B2%D0%B5%D0%B1-%D1%81%D0%B5%D1%80%D0%B2%D0%B5%D1%80-%D0%B8%D1%89%D0%B5%D0%BC-%D0%BB%D1%83%D1%87%D1%88%D0%B8%D0%B9-%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D0%BD%D1%82.6532/">forum.amperka.ru</a></li>
<li>Стример <code>uvc2http</code> <a href="https://habr.com/ru/post/386273/">habr.com</a>, <a href="https://github.com/urpylka/uvc2http">github.com</a></li>
<li>opencv programs <a href="https://stackoverflow.com/questions/34588464/python-how-to-capture-image-from-webcam-on-click-using-opencv">stackoverflow.com</a>, <a href="https://github.com/kevinam99/capturing-images-from-webcam-using-opencv-python/blob/master/webcam-capture-v1.01.py">github.com</a>, <a href="https://techoverflow.net/2018/12/18/how-to-set-cv2-videocapture-image-size/">techoverflow.net</a>, <a href="https://%D0%BB%D0%B8%D0%BD%D1%83%D0%BA%D1%81%D0%B1%D0%BB%D0%BE%D0%B3.%D1%80%D1%84/opencv-python-web-camera/">линуксблог.рф</a>, opencv + flask <a href="https://www.pyimagesearch.com/2019/09/02/opencv-stream-video-to-web-browser-html-page/">pyimagesearch.com</a></li>
<li><a href="https://www.linux.org.ru/tag/h264?section=2&amp;offset=20">Ветки про кодирование H.264 linux.org.ru</a></li>
<li>NavIO streaming manual <a href="http://web.archive.org/web/20201020062824/https://docs.emlid.com/navio2/common/dev/video-streaming/">docs.emlid.com</a></li>
</ul>

            </div>

            <div class="tags">
                 
                <ul class="flat">
                    
                    <li><a href="/tags/ru">ru</a></li>
                    
                    <li><a href="/tags/programming">programming</a></li>
                    
                    <li><a href="/tags/raspberrypi">raspberrypi</a></li>
                    
                    <li><a href="/tags/camera">camera</a></li>
                    
                    <li><a href="/tags/videocapture">videocapture</a></li>
                    
                </ul>
                 
            </div><div id="disqus_thread"></div>
<script type="text/javascript">
	(function () {
		
		
		if (window.location.hostname == "localhost")
			return;

		var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
		var disqus_shortname = 'urpylka';
		dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
		(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
	})();
</script>
<noscript>Please enable JavaScript to view the </a></noscript>
<a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>
    </div>
    <div class="footer wrapper">
	<nav class="nav">
		<div>2021  © Artem Smirnov |  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div><script>feather.replace()</script>
</body>

</html>